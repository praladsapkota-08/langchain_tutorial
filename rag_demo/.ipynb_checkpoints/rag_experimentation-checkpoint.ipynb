{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c021da-d61f-4452-a991-2e71425ed306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install PyPDF2\n",
    "# !pip install langchain\n",
    "# !pip install --upgrade langchain\n",
    "# !pip install -U langchain-text-splitters\n",
    "# !pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c8b518-0fe7-4e1e-ba48-72c33f90e821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0724e2e8-745b-4a71-869e-89f53f49c958",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = './data/book.pdf'\n",
    "reader = PdfReader(pdf_path) # it creates object of pdfreader where pdf is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ec45a2-990e-4174-83ea-da9335c287e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_page = reader.pages[30] # .page reads the content \n",
    "print(first_page)\n",
    "text = first_page.extract_text() # .extract_text extract the text from the page and it doesnt read img \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ad8fc6-0312-4907-8547-4d9d551a7ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('first page text:\\n')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4664e0-c702-405e-8986-6b24692a9e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b105b8bc-e479-4824-ba9f-7d92db97d1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = './data/book.pdf'\n",
    "reader = PdfReader(pdf_path)\n",
    "print(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03bd200-56bf-455d-be28-6dbd0ff8644d",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = []\n",
    "\n",
    "for i, page in enumerate(reader.pages[30:35]):\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        doc = Document(\n",
    "            page_content=text,\n",
    "            metadata = {'page_number' : i + 1, 'source': pdf_path}\n",
    "        )\n",
    "        document.append(doc)\n",
    "\n",
    "print('page sonten preview:\\n',document[2].page_content)\n",
    "print('metadata:\\n',document[2].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41571036-fb9e-43f4-817e-327dbacb6399",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2cc8f7-3fd6-4ae1-8b18-a5f9d428578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 50\n",
    ")\n",
    "\n",
    "chunks = splitter.split_documents(document)\n",
    "\n",
    "print('total chunks created: \\n', len(chunks))\n",
    "print('first chunk preview: \\n', chunks[2].page_content)\n",
    "print('metadata of first chunk: \\n', chunks[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54fffe0-fd53-4995-9cb6-a587822d4f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7f0480-ecef-4b5c-ae77-588230d4f9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "HF_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name =\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "sample_chunks = chunks[:3]\n",
    "embeddings = embedding_model.embed_documents([chunk.page_content for chunk in sample_chunks])\n",
    "\n",
    "print(\"Number of embeddings created:\", len(embeddings)) \n",
    "print(\"Length of one embedding vector:\", len(embeddings[0])) \n",
    "print(\"First 10 values of first embedding:\\n\", embeddings[0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb83f75-c54d-4a31-b3c7-7b278c32be7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3459bed7-bf2a-4931-a8c3-aa3d3bde9b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name =\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "vectorstore = FAISS.from_documents(chunks, embedding_model)\n",
    "\n",
    "vectorstore.save_local('faiss_index')\n",
    "\n",
    "print('FAISS index created and saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59d714f-87f7-4b04-a548-d374ec17353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'why machine learning is used'\n",
    "query1 = 'Why Use Machine Learning?'\n",
    "\n",
    "results = vectorstore.similarity_search(query, k =3)\n",
    "results1 = vectorstore.similarity_search(query1, k =3)\n",
    "\n",
    "for i, res in enumerate(results):\n",
    "    print(f'\\n-------- Results {i + 1} -------')\n",
    "    print('page content preview: \\n', res.page_content[:300])\n",
    "    print('metadata: \\n', res.metadata)\n",
    "\n",
    "print('\\n\\n\\n')\n",
    "\n",
    "for i, res in enumerate(results1):\n",
    "    print(f'\\n-------- Results {i + 1} -------')\n",
    "    print('page content preview: \\n', res.page_content[:300])\n",
    "    print('metadata: \\n', res.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614ca149-8269-4a79-8f9e-b98521826444",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5950216b-d346-4c10-b164-4ee2eefae702",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db50720-bb31-4131-b0e9-2348b9c24781",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\" You are a helpful assistant. \n",
    "Answer the question strictly using the provided context. \n",
    "If the answer is not in the context, say \"I don't know.\" \n",
    "\n",
    "Context: \n",
    "{context} \n",
    "\n",
    "Question: \n",
    "{question} \n",
    "\n",
    "Answer: \n",
    "\"\"\"\n",
    "\n",
    "query = 'Why Use Machine Learning?'\n",
    "\n",
    "results = vectorstore.similarity_search(query, k=3)\n",
    "context = '\\n\\n'.join([res.page_content for res in results])\n",
    "\n",
    "prompt = prompt_template.format(context=context, question=query)\n",
    "\n",
    "answer = qa_pipeline(prompt, max_length = 200)[0]['generated_text']\n",
    "\n",
    "print('final answer:\\n', answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005fdf77-98db-4215-b18f-fed467c5e504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from transformers import pipeline\n",
    "\n",
    "# -----------------------------\n",
    "# Define the RAG pipeline\n",
    "# -----------------------------\n",
    "def rag_pipeline(pdf_path: str, query: str, start_page: int = 0, end_page: int = 5):\n",
    "    # Step 1: Read PDF\n",
    "    reader = PdfReader(pdf_path)\n",
    "    documents = []\n",
    "    for i, page in enumerate(reader.pages[start_page:end_page]):\n",
    "        text = page.extract_text()\n",
    "        if text:\n",
    "            doc = Document(\n",
    "                page_content=text,\n",
    "                metadata={\"page_number\": i + start_page + 1, \"source\": pdf_path}\n",
    "            )\n",
    "            documents.append(doc)\n",
    "\n",
    "    # Step 2: Split into chunks\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    chunks = splitter.split_documents(documents)\n",
    "\n",
    "    # Step 3: Create embeddings\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    vectorstore = FAISS.from_documents(chunks, embedding_model)\n",
    "\n",
    "    # Step 4: Similarity search\n",
    "    results = vectorstore.similarity_search(query, k=3)\n",
    "    context = \"\\n\\n\".join([res.page_content for res in results])\n",
    "\n",
    "    # Step 5: Strict prompt\n",
    "    prompt_template = \"\"\"You are a helpful assistant.\n",
    "Answer the question strictly using the provided context.\n",
    "If the answer is not in the context, say \"I don't know.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "    prompt = prompt_template.format(context=context, question=query)\n",
    "\n",
    "    # Step 6: Generation with Flan-T5\n",
    "    qa_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\")\n",
    "    answer = qa_pipeline(prompt, max_length=200)[0][\"generated_text\"]\n",
    "\n",
    "    return answer, results\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Example usage\n",
    "# -----------------------------\n",
    "pdf_path = \"./data/book.pdf\"\n",
    "query = \"Why Use Machine Learning?\"\n",
    "\n",
    "final_answer, retrieved_chunks = rag_pipeline(pdf_path, query, start_page=30, end_page=35)\n",
    "\n",
    "print(\"\\nFinal Answer:\\n\", final_answer)\n",
    "print(\"\\nRetrieved Chunks Metadata:\")\n",
    "for res in retrieved_chunks:\n",
    "    print(res.metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20e53aa-4abb-41e5-b6b0-d897f3f46b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from transformers import pipeline\n",
    "\n",
    "# -----------------------------\n",
    "# Define the RAG pipeline\n",
    "# -----------------------------\n",
    "def rag_pipeline(pdf_path: str, query: str, start_page: int = 0, end_page: int = 5):\n",
    "    print(\"Step 1: Reading PDF pages...\")\n",
    "    reader = PdfReader(pdf_path)\n",
    "    documents = []\n",
    "    for i, page in enumerate(reader.pages[start_page:end_page]):\n",
    "        text = page.extract_text()\n",
    "        if text:\n",
    "            doc = Document(\n",
    "                page_content=text,\n",
    "                metadata={\"page_number\": i + start_page + 1, \"source\": pdf_path}\n",
    "            )\n",
    "            documents.append(doc)\n",
    "    print(f\"âœ… Extracted {len(documents)} pages of text from PDF.\")\n",
    "\n",
    "    print(\"\\nStep 2: Splitting documents into chunks...\")\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    chunks = splitter.split_documents(documents)\n",
    "    print(f\"âœ… Created {len(chunks)} text chunks.\")\n",
    "\n",
    "    print(\"\\nStep 3: Creating embeddings...\")\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    vectorstore = FAISS.from_documents(chunks, embedding_model)\n",
    "    print(\"âœ… Embeddings generated and stored in FAISS vector database.\")\n",
    "\n",
    "    print(\"\\nStep 4: Performing similarity search...\")\n",
    "    results = vectorstore.similarity_search(query, k=3)\n",
    "    print(f\"âœ… Retrieved {len(results)} most relevant chunks for the query.\")\n",
    "\n",
    "    context = \"\\n\\n\".join([res.page_content for res in results])\n",
    "\n",
    "    print(\"\\nStep 5: Building strict prompt...\")\n",
    "    prompt_template = \"\"\"You are a helpful assistant.\n",
    "Answer the question strictly using the provided context.\n",
    "If the answer is not in the context, say \"I don't know.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "    prompt = prompt_template.format(context=context, question=query)\n",
    "    print(\"âœ… Prompt prepared for generation.\")\n",
    "\n",
    "    print(\"\\nStep 6: Generating answer with Flan-T5...\")\n",
    "    qa_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\")\n",
    "    answer = qa_pipeline(prompt, max_length=200)[0][\"generated_text\"]\n",
    "    print(\"âœ… Answer generated successfully.\")\n",
    "\n",
    "    return answer, results\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Example usage\n",
    "# -----------------------------\n",
    "pdf_path = \"./data/book.pdf\"\n",
    "query = \"Why Use Machine Learning?\"\n",
    "\n",
    "print(\"\\nðŸš€ Starting RAG pipeline...\\n\")\n",
    "final_answer, retrieved_chunks = rag_pipeline(pdf_path, query, start_page=30, end_page=35)\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\"Final Answer:\\n\", final_answer)\n",
    "print(\"==============================\")\n",
    "print(\"\\nRetrieved Chunks Metadata:\")\n",
    "for res in retrieved_chunks:\n",
    "    print(res.metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dd4c08-d3eb-47f4-87e2-a92648f9dc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from transformers import pipeline\n",
    "\n",
    "# -----------------------------\n",
    "# Define the RAG pipeline for TXT\n",
    "# -----------------------------\n",
    "def rag_pipeline_txt(txt_path: str, query: str):\n",
    "    print(\"Step 1: Reading TXT file...\")\n",
    "    with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    print(f\"âœ… Loaded text file: {txt_path} (length: {len(text)} characters)\")\n",
    "\n",
    "    print(\"\\nStep 2: Wrapping into a Document...\")\n",
    "    documents = [Document(page_content=text, metadata={\"source\": txt_path})]\n",
    "    print(f\"âœ… Created {len(documents)} Document object.\")\n",
    "\n",
    "    print(\"\\nStep 3: Splitting into chunks...\")\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    chunks = splitter.split_documents(documents)\n",
    "    print(f\"âœ… Split into {len(chunks)} chunks.\")\n",
    "\n",
    "    print(\"\\nStep 4: Creating embeddings...\")\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    vectorstore = FAISS.from_documents(chunks, embedding_model)\n",
    "    print(\"âœ… Embeddings generated and stored in FAISS vector database.\")\n",
    "\n",
    "    print(\"\\nStep 5: Performing similarity search...\")\n",
    "    results = vectorstore.similarity_search(query, k=3)\n",
    "    print(f\"âœ… Retrieved {len(results)} most relevant chunks for the query.\")\n",
    "\n",
    "    context = \"\\n\\n\".join([res.page_content for res in results])\n",
    "\n",
    "    print(\"\\nStep 6: Building strict prompt...\")\n",
    "    prompt_template = \"\"\"You are a helpful assistant.\n",
    "Answer the question strictly using the provided context.\n",
    "If the answer is not in the context, say \"I don't know.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "    prompt = prompt_template.format(context=context, question=query)\n",
    "    print(\"âœ… Prompt prepared for generation.\")\n",
    "\n",
    "    print(\"\\nStep 7: Generating answer with Flan-T5...\")\n",
    "    qa_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\")\n",
    "    answer = qa_pipeline(prompt, max_length=200)[0][\"generated_text\"]\n",
    "    print(\"âœ… Answer generated successfully.\")\n",
    "\n",
    "    return answer, results\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Example usage\n",
    "# -----------------------------\n",
    "txt_path = \"./data/educational_corpus.txt\"\n",
    "query = \"Explain the Renaissance.\"\n",
    "\n",
    "print(\"\\nðŸš€ Starting RAG pipeline for TXT...\\n\")\n",
    "final_answer, retrieved_chunks = rag_pipeline_txt(txt_path, query)\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\"Final Answer:\\n\", final_answer)\n",
    "print(\"==============================\")\n",
    "print(\"\\nRetrieved Chunks Metadata:\")\n",
    "for res in retrieved_chunks:\n",
    "    print(res.metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f3f717-9dad-425d-aaa7-4de20344fe42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Starting RAG pipeline for TXT...\n",
      "\n",
      "Step 1: Reading TXT file...\n",
      "âœ… Loaded text file: ./data/ott_subscription_faq.txt (length: 2904 characters)\n",
      "\n",
      "Step 2: Wrapping into a Document...\n",
      "âœ… Created 1 Document object.\n",
      "\n",
      "Step 3: Splitting into chunks...\n",
      "âœ… Split into 78 chunks.\n",
      "\n",
      "Step 4: Creating embeddings...\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from transformers import pipeline\n",
    "\n",
    "# -----------------------------\n",
    "# Define the RAG pipeline for TXT\n",
    "# -----------------------------\n",
    "def rag_pipeline_txt(txt_path: str, query: str):\n",
    "    print(\"Step 1: Reading TXT file...\")\n",
    "    with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    print(f\"âœ… Loaded text file: {txt_path} (length: {len(text)} characters)\")\n",
    "\n",
    "    print(\"\\nStep 2: Wrapping into a Document...\")\n",
    "    documents = [Document(page_content=text, metadata={\"source\": txt_path})]\n",
    "    print(f\"âœ… Created {len(documents)} Document object.\")\n",
    "\n",
    "    print(\"\\nStep 3: Splitting into chunks...\")\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=5)\n",
    "    chunks = splitter.split_documents(documents)\n",
    "    print(f\"âœ… Split into {len(chunks)} chunks.\")\n",
    "\n",
    "    print(\"\\nStep 4: Creating embeddings...\")\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    vectorstore = FAISS.from_documents(chunks, embedding_model)\n",
    "    print(\"âœ… Embeddings generated and stored in FAISS vector database.\")\n",
    "\n",
    "    print(\"\\nStep 5: Performing similarity search...\")\n",
    "    results = vectorstore.similarity_search(query, k=3)\n",
    "    # for i, res in enumerate(results):\n",
    "    #     print(f'\\n-------- Results {i + 1} -------')\n",
    "    #     print('page content preview: \\n', res.page_content[:300])\n",
    "    #     print('metadata: \\n', res.metadata)\n",
    "\n",
    "    print(f\"âœ… Retrieved {len(results)} most relevant chunks for the query.\")\n",
    "\n",
    "    context = \"\\n\\n\".join([res.page_content for res in results])\n",
    "\n",
    "    print(\"\\nStep 6: Building strict prompt...\")\n",
    "    prompt_template = \"\"\"You are a helpful assistant.\n",
    "Answer the question strictly using the provided context.\n",
    "If the answer is not in the context, say \"I don't know.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "    prompt = prompt_template.format(context=context, question=query)\n",
    "    print(\"âœ… Prompt prepared for generation.\")\n",
    "\n",
    "    print(\"\\nStep 7: Generating answer with Flan-T5...\")\n",
    "    qa_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\")\n",
    "    answer = qa_pipeline(prompt, max_length=200)[0][\"generated_text\"]\n",
    "    print(\"âœ… Answer generated successfully.\")\n",
    "\n",
    "    return answer, results\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Example usage\n",
    "# -----------------------------\n",
    "txt_path = \"./data/ott_subscription_faq.txt\"\n",
    "query = \"Netflix price\"\n",
    "\n",
    "print(\"\\nðŸš€ Starting RAG pipeline for TXT...\\n\")\n",
    "final_answer, retrieved_chunks = rag_pipeline_txt(txt_path, query)\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\"Final Answer:\\n\", final_answer)\n",
    "print(\"==============================\")\n",
    "print(\"\\nRetrieved Chunks Metadata:\")\n",
    "for res in retrieved_chunks:\n",
    "    print(res.metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a7e1de-7019-427c-a423-6d719722094e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
